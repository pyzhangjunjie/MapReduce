package com.atguigu.flowsum;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;import java.io.IOException;public class Driver {        public static void main(String[] args) throws IOException, InterruptedException, ClassNotFoundException {            //1.获取配置信息及分装任务            Configuration configuration = new Configuration();            configuration.set("fs.defaultFS", "hdfs://hadoop102:8020");            configuration.set("mapreduce.framework.name", "yarn");            configuration.set("mapreduce.app-submission.cross-platform","true");            configuration.set("yarn.resourcemanager.hostname","hadoop103");            Job job = Job.getInstance(configuration);            //2.设置jar路径            //job.setJarByClass(Driver.class);            job.setJar("C:\\Users\\Administrator\\IdeaProjects\\MapReduce\\target\\WordCount-1.0-SNAPSHOT.jar");            //3.设置map和reduce类            job.setMapperClass(Mapper.class);            job.setReducerClass(Reducer.class);            //4.设置map输出类            job.setMapOutputKeyClass(LongWritable.class);            job.setMapOutputValueClass(FlowBean.class);            //5.最终输出类            job.setOutputKeyClass(LongWritable.class);            job.setOutputValueClass(FlowBean.class);            //6.设置输入，输出路径            FileInputFormat.setInputPaths(job, new Path(args[0]));            FileOutputFormat.setOutputPath(job, new Path(args[1]));            //7. 提交任务            boolean b = job.waitForCompletion(true);            System.exit(b ? 0 : 1);        }}